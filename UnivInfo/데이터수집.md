# 데이터 수집 보고서

### **1. 라이브러리 및 초기 설정**

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
```

**사용 라이브러리**:

- selenium: 웹 브라우저를 자동으로 제어하여 JavaScript로 동적으로 로드되는 콘텐츠를 가져옴
- BeautifulSoup: HTML 콘텐츠를 파싱하고 데이터 추출을 간편하게 처리
- googlemaps: Google Maps API를 호출해 위치 정보를 얻음

---

### **2. Selenium WebDriver 설정**

```python
options = webdriver.ChromeOptions()
options.add_argument("--headless")  # 브라우저 창을 띄우지 않음
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
driver = webdriver.Chrome(options=options)
```

- **코드 설명**:
    - -headless: 브라우저 창을 띄우지 않고 백그라운드에서 동작하도록 설정
    - -no-sandbox 및 -disable-dev-shm-usage: 리소스 제한 환경에서 안정적으로 실행하기 위한 설정
    - WebDriver 객체를 생성해 웹 브라우저를 제어

---

### **3. 웹페이지 로드 및 특정 요소 대기**

```python
url = "https://namu.wiki/w/%EC%BA%A0%ED%8D%BC%EC%8A%A4"
driver.get(url)

try:
    WebDriverWait(driver, 30).until(
        EC.presence_of_element_located((By.CLASS_NAME, "_1CbAe5Lw"))
    )
    print("특정 div가 로드되었습니다.")
except:
    print("특정 div 로드 실패.")
    driver.quit()
    exit()
```

- **코드 설명**:
    - driver.get(url): 지정된 URL로 웹 페이지를 로드.
    - WebDriverWait: 페이지가 완전히 로드될 때까지 최대 30초 대기
    - presence_of_element_located: 특정 클래스 이름이 있는 요소가 페이지에 나타나는지 확인
    - 예외 발생 시 드라이버를 종료하고 프로그램을 종료

---

### **4. BeautifulSoup으로 HTML 파싱 및 데이터 추출**

```python
html = driver.page_source
soup = BeautifulSoup(html, "html.parser")
tables = soup.find_all("table", {"class": "xZl7LbPm _ba832eed82a14e6b3bc9304cd9b2a6d0"})
```

**코드 설명**:

- driver.page_source: Selenium에서 로드된 페이지의 HTML 소스를 가져옴.
- BeautifulSoup: HTML을 파싱하여 DOM 구조로 변환.
- find_all: 특정 클래스명을 가진 모든 <table> 요소를 검색.

```python
for index in [2, 3]:
    if index < len(tables):
        table = tables[index]
        rows = table.find("tbody").find_all("tr")
        for row in rows[1:]:
            columns = row.find_all("td")
            if len(columns) >= 4:
                name_div = columns[1].find("div", {"class": "W4-ZFyxd"})
                area_div = columns[3].find("div", {"class": "W4-ZFyxd"})
                if name_div and area_div:
                    name = name_div.get_text(strip=True)
                    area = area_div.get_text(strip=True)
                    all_university_data.append({"대학명": name, "면적": area})
```

- **코드 설명**:
    - for index in [2, 3]: 필요한 데이터가 포함된 테이블(3번, 4번)을 선택적으로 접근
        - 가져오려고 한 특정 테이블의 class만에 접근하려했으나, 해당 페이지의 table명과, table을 감싼 div태그의 class명이 모두 일치했음 따라서 모든 table을 가져온 후 필요한 데이터의 테이블(3,4)에 접근하도록 코드를 작성함
    - rows[1:]: 헤더 행을 제외하고 데이터 행만 처리.
    - 대학교 이름과 면적 데이터를 all_university_data 리스트에 저장.

---

### **5. Google Maps Geocoding API를 활용한 위치 정보 추가**

```python
load_dotenv()
api_key = os.getenv('GOOGLE_API_KEY')
gmaps = googlemaps.Client(key=api_key)
```
**코드 설명**:

- load_dotenv: .env 파일에서 환경 변수를 로드 → github에 key가 업로드 되는 것을 방지하기 위해 .env 파일에 key작성 후 불러오는 방식으로 작성
- os.getenv('GOOGLE_API_KEY'): Google Maps API Key를 안전하게 불러옴
- googlemaps.Client: API 호출을 위한 클라이언트 객체 생성

```python
for data in all_university_data:
    try:
        geocode_result = gmaps.geocode(data['대학명'], language='ko')
        if geocode_result:
            location = geocode_result[0]['geometry']['location']
            latitude = location['lat']
            longitude = location['lng']
            university_locations.append({
                "대학명": data['대학명'],
                "면적": data['면적'],
                "위도": latitude,
                "경도": longitude
            })
    except Exception as e:
        print(f"{data['대학명']}: 오류 발생 - {e}")
```

**코드 설명**:

- gmaps.geocode: 대학교 이름으로 위치 정보를 검색
- location['lat'], location['lng']: 검색된 위치의 위도와 경도 값 추출

---

### **6. 전체 코드의 동작 흐름**

1. Selenium으로 URL의 HTML 콘텐츠를 가져오고 동적으로 로드되는 데이터를 대기
2. BeautifulSoup을 사용해 특정 클래스명을 가진 테이블의 데이터를 파싱
3. 대학교 이름과 면적 데이터를 추출
4. Google Maps Geocoding API를 사용해 위도 및 경도를 추가
5. 최종 데이터를 university_locations 리스트에 저장

### **7.DataFrame 생성 및 CSV 파일 저장**

### **7-1. 데이터프레임 생성**

```python
df = pd.DataFrame(university_locations)
```

**설명**:

- pd.DataFrame: Pandas 라이브러리를 사용하여 데이터를 테이블 형식의 데이터프레임(DataFrame)으로 변환
- university_locations: 이전에 수집한 대학교 데이터(이름, 면적, 위도, 경도)가 포함된 리스트
- 리스트 내 딕셔너리 구조를 기반으로 자동으로 열(Column)이 생성되며, 각각의 딕셔너리 키가 열 이름이 되고 값이 행 데이터로 들어감
- **예시**:
    - university_locations 리스트:
        
        
```python
        [
            {"대학명": "서울대학교", "면적": "500,000㎡", "위도": 37.459882, "경도": 126.951905},
            {"대학명": "고려대학교", "면적": "300,000㎡", "위도": 37.589287, "경도": 127.033503}
]

```        
- 변환 후 DataFrame:

```
대학명           면적           위도            경도
        0  서울대학교   500,000㎡  37.459882  126.951905
        1  고려대학교   300,000㎡  37.589287  127.033503
```
        

---

### **7-2. CSV 파일로 저장**

```python
df.to_csv("university_locations.csv", index=False, encoding="utf-8-sig")
```

- **설명**:
    - df.to_csv: 데이터를 CSV 파일로 저장하는 Pandas 메서드
    - index=False: DataFrame의 인덱스를 CSV 파일에 포함하지 않도록 설정.
        - 기본적으로 DataFrame은 각 행에 인덱스를 포함하지만, 데이터 분석에서는 불필요한 경우가 많아 제외
